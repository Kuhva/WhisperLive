FROM python:3.12-bookworm

ARG DEBIAN_FRONTEND=noninteractive

# install lib required for pyaudio
RUN apt update && apt install -y portaudio19-dev && apt-get clean && rm -rf /var/lib/apt/lists/*

# update pip to support for whl.metadata -> less downloading
RUN pip install --no-cache-dir -U "pip>=24"

# create a working directory
RUN mkdir /app
WORKDIR /app

# Install Transformers and dependencies
RUN pip install --no-cache-dir transformers[torch]>=4.23 ctranslate2

# Convert Whisper model
RUN python -m ctranslate2.converters.transformers \
    --model openai/whisper-large-v3-turbo \
    --output_dir whisper-large-v3-turbo-ct2 \
    --copy_files tokenizer.json preprocessor_config.json \
    --quantization float16

# install the requirements for running the whisper-live server
COPY requirements/server.txt /app/
RUN pip install --no-cache-dir -r server.txt && rm server.txt

# make the paths of the nvidia libs installed as wheels visible. equivalent to:
# export LD_LIBRARY_PATH=`python3 -c 'import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + ":" + os.path.dirname(nvidia.cudnn.lib.__file__))'`
ENV LD_LIBRARY_PATH="/usr/local/lib/python3.12/site-packages/nvidia/cublas/lib:/usr/local/lib/python3.12/site-packages/nvidia/cudnn/lib"

COPY whisper_live /app/whisper_live
COPY run_server.py /app

CMD ["python", "run_server.py", "-fw", "./whisper-large-v3-turbo-ct2"]
EXPOSE 9090
